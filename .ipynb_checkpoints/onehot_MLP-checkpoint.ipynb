{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    480452\n",
       "2    480452\n",
       "1    480452\n",
       "0    480452\n",
       "Name: CRASH_SEV_CODE, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "#df = pd.read_csv(\"C:\\\\Users\\Eric\\Desktop\\crash_data_one_hot_encoded_MLP.csv\")\n",
    "df = pd.read_csv(\"crash_data_no_unknowns_clustered.csv\")\n",
    "df2 = pd.read_csv(\"crash_data_only_numeric_values.csv\")\n",
    "\n",
    "#add crash_sev_code to one_hot_encoded\n",
    "df = df.assign(CRASH_SEV_CODE = df2[\"CRASH_SEV_CODE\"])\n",
    "df.drop('CRASH_SEV_F', axis='columns', inplace=True)\n",
    "df.drop('CRASH_SEV_M', axis='columns', inplace=True)\n",
    "df.drop('CRASH_SEV_N', axis='columns', inplace=True)\n",
    "df.drop('CRASH_SEV_S', axis='columns', inplace=True)\n",
    "#for cluster_scaled\n",
    "df.drop('CLUSTER', axis='columns', inplace=True)\n",
    "#for cluster\n",
    "#df.drop('CLUSTER_SCALED', axis='columns', inplace=True)\n",
    "\n",
    "df = sklearn.utils.shuffle(df)\n",
    "df.fillna(0,inplace=True)\n",
    "encode = LabelEncoder()\n",
    "\n",
    "#features = ['CRASH_YEAR', 'NUM_LANES', 'SPD_LIM', 'MULTI_VEH_CODE','HOLIDAY_CODE',\n",
    "#            'LG_REGION_DESC_CODE', 'JUNCTION_TYPE_CODE', 'DIRN_ROLE1_DESC_CODE','INTSN_MIDBLOCK_CODE',\n",
    "#            'FLAT_HILL_CODE','ROAD_CURVATURE_CODE','ROAD_MARKINGS_CODE','ROAD_SURFACE_CODE','ROAD_WET_CODE',\n",
    "#            'URBAN_CODE','LIGHT_CODE','STREET_LIGHT_CODE','WEATHER_A_CODE']\n",
    "\n",
    "features = ['CRASH_YEAR', \n",
    "'NUM_LANES', \n",
    "'SPD_LIM', \n",
    "'TRAFFIC_CTRL_Give Way Sign', \n",
    "'TRAFFIC_CTRL_Nil', \n",
    "'TRAFFIC_CTRL_Points Man', \n",
    "'TRAFFIC_CTRL_School Patrol', \n",
    "'TRAFFIC_CTRL_Stop Sign', \n",
    "'TRAFFIC_CTRL_Traffic Signal', \n",
    "'MULTI_VEH_Cyclist(s)+Pedestrian(s) only', \n",
    "'MULTI_VEH_Cyclists only', \n",
    "'MULTI_VEH_Multi vehicle', \n",
    "'MULTI_VEH_Other', \n",
    "'MULTI_VEH_Others without non-parked veh', \n",
    "'MULTI_VEH_Single vehicle', \n",
    "'MULTI_VEH_Vehicle(s)+Cyclist(s) only', \n",
    "'MULTI_VEH_Vehicle(s)+Pedestrian(s)', \n",
    "'MULTI_VEH_Vehicle(s)+multiple other types', \n",
    "'HOLIDAY_Christmas/New Year', \n",
    "'HOLIDAY_Easter', \n",
    "'HOLIDAY_Labour Weekend', \n",
    "'HOLIDAY_None', \n",
    "'HOLIDAY_Queens Birthday', \n",
    "'LG_REGION_DESC_0', \n",
    "'LG_REGION_DESC_Auckland            ', \n",
    "'LG_REGION_DESC_Bay of Plenty       ', \n",
    "'LG_REGION_DESC_Canterbury          ', \n",
    "'LG_REGION_DESC_Gisborne            ', \n",
    "'LG_REGION_DESC_Hawkes Bay          ', \n",
    "'LG_REGION_DESC_Manawatu/Wanganui   ', \n",
    "'LG_REGION_DESC_Nelson/Marlborough  ', \n",
    "'LG_REGION_DESC_Northland           ', \n",
    "'LG_REGION_DESC_Otago               ', \n",
    "'LG_REGION_DESC_Southland           ', \n",
    "'LG_REGION_DESC_Taranaki            ', \n",
    "'LG_REGION_DESC_Waikato             ', \n",
    "'LG_REGION_DESC_Wellington          ', \n",
    "'LG_REGION_DESC_West Coast          ', \n",
    "'JUNCTION_TYPE_Driveway', \n",
    "'JUNCTION_TYPE_Multi Rd Join', \n",
    "'JUNCTION_TYPE_Roundabout', \n",
    "'JUNCTION_TYPE_T Type Junction',  \n",
    "'JUNCTION_TYPE_X Type Junction', \n",
    "'JUNCTION_TYPE_Y Type Junction', \n",
    "'DIRN_ROLE1_DESC_0', \n",
    "'DIRN_ROLE1_DESC_East', \n",
    "'DIRN_ROLE1_DESC_North', \n",
    "'DIRN_ROLE1_DESC_South',  \n",
    "'DIRN_ROLE1_DESC_West', \n",
    "'INTSN_MIDBLOCK_Intersection', \n",
    "'INTSN_MIDBLOCK_Mid Block', \n",
    "'FLAT_HILL_Flat', \n",
    "'FLAT_HILL_Hill',  \n",
    "'ROAD_CURVATURE_Easy Curve', \n",
    "'ROAD_CURVATURE_Moderate Curve', \n",
    "'ROAD_CURVATURE_Severe Curve', \n",
    "'ROAD_CURVATURE_Straight Road',  \n",
    "'ROAD_MARKINGS_Centre Line', \n",
    "'ROAD_MARKINGS_No Marks', \n",
    "'ROAD_MARKINGS_No Passing Lines', \n",
    "'ROAD_MARKINGS_Painted Island', \n",
    "'ROAD_MARKINGS_Ped Crossing', \n",
    "'ROAD_MARKINGS_Raised Island', \n",
    "'ROAD_SURFACE_Sealed', \n",
    "'ROAD_SURFACE_Unsealed', \n",
    "'ROAD_WET_Dry', \n",
    "'ROAD_WET_Ice/ Snow', \n",
    "'ROAD_WET_Wet', \n",
    "'URBAN_Openroad', \n",
    "'URBAN_Urban', \n",
    "'LIGHT_Bright Sun', \n",
    "'LIGHT_Dark', \n",
    "'LIGHT_Overcast', \n",
    "'LIGHT_Twilight',  \n",
    "'STREET_LIGHT_None', \n",
    "'STREET_LIGHT_Off', \n",
    "'STREET_LIGHT_On',  \n",
    "'WEATHER_A_Fine', \n",
    "'WEATHER_A_Heavy Rain', \n",
    "'WEATHER_A_Light Rain', \n",
    "'WEATHER_A_Mist', \n",
    "'WEATHER_A_Snow',\n",
    "'CLUSTER_SCALED']\n",
    "\n",
    "df_non_injury = df[df.CRASH_SEV_CODE==2]  # 480452 samples\n",
    "df_minor = df[df.CRASH_SEV_CODE==1]       # 150834 samples\n",
    "df_serious = df[df.CRASH_SEV_CODE==3]    # 37347  samples\n",
    "df_fatal = df[df.CRASH_SEV_CODE==0]       # 6178   samples\n",
    "\n",
    "df_minor_upsampled = resample(df_minor, replace=True,n_samples=480452,random_state=40)\n",
    "df_serious_upsampled = resample(df_serious, replace=True,n_samples=480452,random_state=40)\n",
    "df_fatal_upsampled = resample(df_fatal, replace=True,n_samples=480452,random_state=40)\n",
    "\n",
    "df_upsampled = pd.concat([df_non_injury, df_minor_upsampled, df_serious_upsampled, df_fatal_upsampled])\n",
    "\n",
    "df_upsampled.CRASH_SEV_CODE.value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1729627, 83)\n",
      "(192181, 83)\n"
     ]
    }
   ],
   "source": [
    "X = df_upsampled.drop([\"CRASH_SEV_CODE\"], axis=1).values\n",
    "y = df_upsampled[\"CRASH_SEV_CODE\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=40)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.40126450\n",
      "Iteration 2, loss = 1.38632572\n",
      "Iteration 3, loss = 1.38632696\n",
      "Iteration 4, loss = 1.38632417\n",
      "Iteration 5, loss = 1.38632797\n",
      "Iteration 6, loss = 1.38632479\n",
      "Iteration 7, loss = 1.38632376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jaedyn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training time: 97.18539381027222s\n",
      "\n",
      " training data\n",
      "\n",
      "[[432400      0      0      0]\n",
      " [432467      0      0      0]\n",
      " [432632      0      0      0]\n",
      " [432128      0      0      0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40    432400\n",
      "\n",
      "   micro avg       0.25      1.00      0.40    432400\n",
      "   macro avg       0.25      1.00      0.40    432400\n",
      "weighted avg       0.25      1.00      0.40    432400\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " test data\n",
      "\n",
      "[[48052     0     0     0]\n",
      " [47985     0     0     0]\n",
      " [47820     0     0     0]\n",
      " [48324     0     0     0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40     48052\n",
      "\n",
      "   micro avg       0.25      1.00      0.40     48052\n",
      "   macro avg       0.25      1.00      0.40     48052\n",
      "weighted avg       0.25      1.00      0.40     48052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(84,42,1), activation='relu', solver='adam', max_iter=500,verbose = True)\n",
    "\n",
    "start = time.time()\n",
    "mlp.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)\n",
    "print(f\"\\n Training time: {stop - start}s\")\n",
    "print(\"\\n training data\\n\")\n",
    "print(confusion_matrix(y_train,predict_train))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train,predict_train,labels=pd.unique(predict_train)))\n",
    "print(\"\\n---------------------------------------------------------------------------------------\\n\")\n",
    "print(\"\\n test data\\n\")\n",
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,predict_test,labels=pd.unique(predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "classification_report(y_test,predict_test,labels=pd.unique(predict_test))\n",
    "print(mlp.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1-- Epoch 1\n",
      "\n",
      "-- Epoch 1-- Epoch 1\n",
      "\n",
      "Norm: 195158.69, NNZs: 18, Bias: 23.000000, T: 1921808, Avg. loss: 686148.332722\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 82456.47, NNZs: 18, Bias: -59.000000, T: 1921808, Avg. loss: 745568.259439\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 116749.24, NNZs: 18, Bias: -29.000000, T: 1921808, Avg. loss: 744053.898060\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 78961.63, NNZs: 18, Bias: 11.000000, T: 1921808, Avg. loss: 672685.401437\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 281231.62, NNZs: 18, Bias: 43.000000, T: 3843616, Avg. loss: 668819.152235\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 128339.92, NNZs: 18, Bias: -118.000000, T: 3843616, Avg. loss: 743692.985429\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 164033.92, NNZs: 18, Bias: -53.000000, T: 3843616, Avg. loss: 736939.681098\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 94703.29, NNZs: 18, Bias: 21.000000, T: 3843616, Avg. loss: 668351.320158\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 281043.54, NNZs: 18, Bias: 62.000000, T: 5765424, Avg. loss: 663922.374089\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 164845.23, NNZs: 18, Bias: -173.000000, T: 5765424, Avg. loss: 742484.267684\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 99212.75, NNZs: 18, Bias: 26.000000, T: 5765424, Avg. loss: 667427.094227\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 180385.45, NNZs: 18, Bias: -71.000000, T: 5765424, Avg. loss: 735944.742280\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 284448.76, NNZs: 18, Bias: 77.000000, T: 7687232, Avg. loss: 666238.806286\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 193309.21, NNZs: 18, Bias: -229.000000, T: 7687232, Avg. loss: 742634.634004\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 178591.61, NNZs: 18, Bias: -90.000000, T: 7687232, Avg. loss: 737281.690980\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 114392.84, NNZs: 18, Bias: 33.000000, T: 7687232, Avg. loss: 667188.410140\n",
      "Total training time: 2.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 267040.42, NNZs: 18, Bias: 92.000000, T: 9609040, Avg. loss: 663701.757230\n",
      "Total training time: 2.48 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 221702.21, NNZs: 18, Bias: -281.000000, T: 9609040, Avg. loss: 740707.935020\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 164507.57, NNZs: 18, Bias: -100.000000, T: 9609040, Avg. loss: 735595.959721\n",
      "Total training time: 2.52 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 128078.52, NNZs: 18, Bias: 41.000000, T: 9609040, Avg. loss: 666085.479523\n",
      "Total training time: 2.53 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 302644.18, NNZs: 18, Bias: 110.000000, T: 11530848, Avg. loss: 665623.670007\n",
      "Total training time: 2.98 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 241944.57, NNZs: 18, Bias: -334.000000, T: 11530848, Avg. loss: 740694.201902\n",
      "Total training time: 3.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 140047.04, NNZs: 18, Bias: 50.000000, T: 11530848, Avg. loss: 665486.938070\n",
      "Total training time: 3.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 179042.76, NNZs: 18, Bias: -114.000000, T: 11530848, Avg. loss: 735330.204818\n",
      "Total training time: 3.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 314326.77, NNZs: 18, Bias: 127.000000, T: 13452656, Avg. loss: 665739.303313\n",
      "Total training time: 3.47 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 256793.20, NNZs: 18, Bias: -389.000000, T: 13452656, Avg. loss: 741833.595219\n",
      "Total training time: 3.48 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 152221.91, NNZs: 18, Bias: 58.000000, T: 13452656, Avg. loss: 664778.554352\n",
      "Total training time: 3.50 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 182794.35, NNZs: 18, Bias: -126.000000, T: 13452656, Avg. loss: 735416.718362\n",
      "Total training time: 3.53 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 312677.48, NNZs: 18, Bias: 146.000000, T: 15374464, Avg. loss: 664718.807071\n",
      "Total training time: 3.95 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 275984.99, NNZs: 18, Bias: -442.000000, T: 15374464, Avg. loss: 740790.088620\n",
      "Total training time: 3.97 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 164044.51, NNZs: 18, Bias: 70.000000, T: 15374464, Avg. loss: 664870.584721\n",
      "Total training time: 4.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 193448.74, NNZs: 18, Bias: -141.000000, T: 15374464, Avg. loss: 736198.512778\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 340929.51, NNZs: 18, Bias: 164.000000, T: 17296272, Avg. loss: 665342.392998\n",
      "Total training time: 4.46 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 291510.20, NNZs: 18, Bias: -492.000000, T: 17296272, Avg. loss: 740458.046660\n",
      "Total training time: 4.47 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 208870.90, NNZs: 18, Bias: -156.000000, T: 17296272, Avg. loss: 735127.921468\n",
      "Total training time: 4.55 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 169751.45, NNZs: 18, Bias: 77.000000, T: 17296272, Avg. loss: 664690.187989\n",
      "Total training time: 4.55 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 315676.18, NNZs: 18, Bias: 178.000000, T: 19218080, Avg. loss: 663358.579583\n",
      "Total training time: 4.94 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 302416.19, NNZs: 18, Bias: -540.000000, T: 19218080, Avg. loss: 741797.961406\n",
      "Total training time: 4.96 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 175227.74, NNZs: 18, Bias: 92.000000, T: 19218080, Avg. loss: 663635.702170\n",
      "Total training time: 5.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 202263.14, NNZs: 18, Bias: -166.000000, T: 19218080, Avg. loss: 736005.228902\n",
      "Total training time: 5.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 346449.83, NNZs: 18, Bias: 199.000000, T: 21139888, Avg. loss: 665030.129319\n",
      "Total training time: 5.44 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 312863.75, NNZs: 18, Bias: -591.000000, T: 21139888, Avg. loss: 740571.519970\n",
      "Total training time: 5.47 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 180994.86, NNZs: 18, Bias: 101.000000, T: 21139888, Avg. loss: 664583.727511\n",
      "Total training time: 5.58 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 204938.66, NNZs: 18, Bias: -182.000000, T: 21139888, Avg. loss: 736162.327586\n",
      "Total training time: 5.60 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 317738.09, NNZs: 18, Bias: 213.000000, T: 23061696, Avg. loss: 663940.773949\n",
      "Total training time: 5.93 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 321529.40, NNZs: 18, Bias: -640.000000, T: 23061696, Avg. loss: 740874.798785\n",
      "Total training time: 5.97 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 194419.59, NNZs: 18, Bias: 114.000000, T: 23061696, Avg. loss: 663942.265932\n",
      "Total training time: 6.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 212689.47, NNZs: 18, Bias: -199.000000, T: 23061696, Avg. loss: 735096.008495\n",
      "Total training time: 6.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 302908.16, NNZs: 18, Bias: 231.000000, T: 24983504, Avg. loss: 663694.587688\n",
      "Total training time: 6.42 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 333625.83, NNZs: 18, Bias: -693.000000, T: 24983504, Avg. loss: 740457.649271\n",
      "Total training time: 6.45 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 192987.60, NNZs: 18, Bias: 125.000000, T: 24983504, Avg. loss: 664458.871953\n",
      "Total training time: 6.59 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 221175.87, NNZs: 18, Bias: -212.000000, T: 24983504, Avg. loss: 734940.608516\n",
      "Total training time: 6.61 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 332653.47, NNZs: 18, Bias: 248.000000, T: 26905312, Avg. loss: 664514.539534\n",
      "Total training time: 6.90 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 339826.06, NNZs: 18, Bias: -743.000000, T: 26905312, Avg. loss: 740865.351133\n",
      "Total training time: 6.94 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 204372.16, NNZs: 18, Bias: 136.000000, T: 26905312, Avg. loss: 663865.339165\n",
      "Total training time: 7.09 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 210676.43, NNZs: 18, Bias: -224.000000, T: 26905312, Avg. loss: 735683.247926\n",
      "Total training time: 7.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 333436.39, NNZs: 18, Bias: 263.000000, T: 28827120, Avg. loss: 665603.929677\n",
      "Total training time: 7.40 seconds.\n",
      "Convergence after 15 epochs took 7.40 seconds\n",
      "Norm: 348727.50, NNZs: 18, Bias: -794.000000, T: 28827120, Avg. loss: 740995.184396\n",
      "Total training time: 7.44 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 212273.65, NNZs: 18, Bias: 153.000000, T: 28827120, Avg. loss: 664268.322590\n",
      "Total training time: 7.58 seconds.\n",
      "Convergence after 15 epochs took 7.58 seconds\n",
      "Norm: 240578.95, NNZs: 18, Bias: -241.000000, T: 28827120, Avg. loss: 734738.726650\n",
      "Total training time: 7.59 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 352970.77, NNZs: 18, Bias: -842.000000, T: 30748928, Avg. loss: 741050.593514\n",
      "Total training time: 7.86 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 251035.54, NNZs: 18, Bias: -258.000000, T: 30748928, Avg. loss: 734902.016352\n",
      "Total training time: 7.99 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 359489.97, NNZs: 18, Bias: -893.000000, T: 32670736, Avg. loss: 741931.772918\n",
      "Total training time: 8.25 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 231948.58, NNZs: 18, Bias: -266.000000, T: 32670736, Avg. loss: 735565.659500\n",
      "Total training time: 8.39 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 370116.30, NNZs: 18, Bias: -944.000000, T: 34592544, Avg. loss: 739542.007891\n",
      "Total training time: 8.62 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 218418.23, NNZs: 18, Bias: -280.000000, T: 34592544, Avg. loss: 735763.668320\n",
      "Total training time: 8.80 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 375234.74, NNZs: 18, Bias: -995.000000, T: 36514352, Avg. loss: 741123.716460\n",
      "Total training time: 9.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 221729.52, NNZs: 18, Bias: -294.000000, T: 36514352, Avg. loss: 735453.782756\n",
      "Total training time: 9.23 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 382739.10, NNZs: 18, Bias: -1048.000000, T: 38436160, Avg. loss: 741434.340264\n",
      "Total training time: 9.45 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 223720.15, NNZs: 18, Bias: -305.000000, T: 38436160, Avg. loss: 735461.767411\n",
      "Total training time: 9.63 seconds.\n",
      "Convergence after 20 epochs took 9.63 seconds\n",
      "Norm: 387854.89, NNZs: 18, Bias: -1103.000000, T: 40357968, Avg. loss: 741370.908337\n",
      "Total training time: 9.84 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 392933.55, NNZs: 18, Bias: -1154.000000, T: 42279776, Avg. loss: 740334.383444\n",
      "Total training time: 10.24 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 399304.38, NNZs: 18, Bias: -1205.000000, T: 44201584, Avg. loss: 740429.665863\n",
      "Total training time: 10.64 seconds.\n",
      "Convergence after 23 epochs took 10.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   10.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   10.6s finished\n"
     ]
    }
   ],
   "source": [
    "# only run this cell and below for feature importance\n",
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=40, verbose=True,n_jobs = -1)\n",
    "clf.fit(X,y)\n",
    "\n",
    "coeffs = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      " min:  -657.505707130214  feature:  ROAD_SURFACE_Unknown \n",
      " max:  37.03248869219892  feature:  MULTI_VEH_Other\n",
      "-------------------\n",
      "-------------------\n",
      " min:  -1315.1133036655588  feature:  DIRN_ROLE1_DESC_0 \n",
      " max:  657.6182417089478  feature:  ROAD_SURFACE_Unknown\n",
      "-------------------\n",
      "-------------------\n",
      " min:  -657.5057071302133  feature:  ROAD_SURFACE_Unknown \n",
      " max:  1315.2258382442915  feature:  DIRN_ROLE1_DESC_0\n",
      "-------------------\n",
      "-------------------\n",
      " min:  -657.5193937681679  feature:  ROAD_SURFACE_Unknown \n",
      " max:  41.12664954461998  feature:  MULTI_VEH_Cyclist(s)+Pedestrian(s) only\n",
      "-------------------\n",
      "\n",
      " training data\n",
      "\n",
      "[[ 94361 101434  51191 185414]\n",
      " [102238 125102 112274  92853]\n",
      " [ 82660 123299 161536  65137]\n",
      " [ 98839 110351  85673 137265]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.22      0.23    432400\n",
      "           2       0.39      0.37      0.38    432632\n",
      "           1       0.27      0.29      0.28    432467\n",
      "           3       0.29      0.32      0.30    432128\n",
      "\n",
      "    accuracy                           0.30   1729627\n",
      "   macro avg       0.30      0.30      0.30   1729627\n",
      "weighted avg       0.30      0.30      0.30   1729627\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " test data\n",
      "\n",
      "[[10569 11318  5664 20501]\n",
      " [11378 13703 12521 10383]\n",
      " [ 9098 13703 17780  7239]\n",
      " [10968 12436  9603 15317]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.22      0.23     48052\n",
      "           2       0.39      0.37      0.38     47820\n",
      "           1       0.27      0.29      0.28     47985\n",
      "           3       0.29      0.32      0.30     48324\n",
      "\n",
      "    accuracy                           0.30    192181\n",
      "   macro avg       0.30      0.30      0.30    192181\n",
      "weighted avg       0.30      0.30      0.30    192181\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.drop([\"CRASH_SEV_CODE\"], axis=1).columns\n",
    "minV = 0\n",
    "maxV = 0\n",
    "minPlace = 0\n",
    "maxPlace = 0\n",
    "count = 0\n",
    "for i in coeffs:\n",
    "    for j in i:\n",
    "        if count == 0:\n",
    "            minPlace = 0\n",
    "            maxPlace = 0\n",
    "            minV = j\n",
    "            maxV = j\n",
    "        else:\n",
    "            if minV > j:\n",
    "                minV =j\n",
    "                minPlace = count\n",
    "            if maxV < j:\n",
    "                maxV = j\n",
    "                maxPlace = count\n",
    "        count+=1\n",
    "    \n",
    "    count = 0\n",
    "    print(\"-------------------\")\n",
    "    print(\" min: \",minV,\" feature: \",features[minPlace],\"\\n max: \",maxV,\" feature: \",features[maxPlace])\n",
    "    print(\"-------------------\")\n",
    "\n",
    "predict_train2 = clf.predict(X_train)\n",
    "predict_test2 = clf.predict(X_test)\n",
    "\n",
    "print(\"\\n training data\\n\")\n",
    "print(confusion_matrix(y_train,predict_train2))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train,predict_train2,labels=pd.unique(predict_train)))\n",
    "print(\"\\n---------------------------------------------------------------------------------------\\n\")\n",
    "print(\"\\n test data\\n\")\n",
    "print(confusion_matrix(y_test,predict_test2))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,predict_test2,labels=pd.unique(predict_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

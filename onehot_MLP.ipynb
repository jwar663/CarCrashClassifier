{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRASH_YEAR</th>\n",
       "      <th>NUM_LANES</th>\n",
       "      <th>SPD_LIM</th>\n",
       "      <th>TRAFFIC_CTRL_Give Way Sign</th>\n",
       "      <th>TRAFFIC_CTRL_Nil</th>\n",
       "      <th>TRAFFIC_CTRL_Points Man</th>\n",
       "      <th>TRAFFIC_CTRL_School Patrol</th>\n",
       "      <th>TRAFFIC_CTRL_Stop Sign</th>\n",
       "      <th>TRAFFIC_CTRL_Traffic Signal</th>\n",
       "      <th>MULTI_VEH_Cyclist(s)+Pedestrian(s) only</th>\n",
       "      <th>...</th>\n",
       "      <th>STREET_LIGHT_Off</th>\n",
       "      <th>STREET_LIGHT_On</th>\n",
       "      <th>STREET_LIGHT_Unknown</th>\n",
       "      <th>WEATHER_A_Fine</th>\n",
       "      <th>WEATHER_A_Heavy Rain</th>\n",
       "      <th>WEATHER_A_Light Rain</th>\n",
       "      <th>WEATHER_A_Mist</th>\n",
       "      <th>WEATHER_A_Snow</th>\n",
       "      <th>WEATHER_A_Unknown</th>\n",
       "      <th>CRASH_SEV_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRASH_YEAR  NUM_LANES  SPD_LIM  TRAFFIC_CTRL_Give Way Sign  \\\n",
       "0        2000          6       50                           0   \n",
       "1        2000          2      100                           0   \n",
       "2        2000          3      100                           0   \n",
       "3        2000          2      100                           0   \n",
       "4        2000          2       70                           0   \n",
       "\n",
       "   TRAFFIC_CTRL_Nil  TRAFFIC_CTRL_Points Man  TRAFFIC_CTRL_School Patrol  \\\n",
       "0                 0                        0                           0   \n",
       "1                 1                        0                           0   \n",
       "2                 1                        0                           0   \n",
       "3                 1                        0                           0   \n",
       "4                 1                        0                           0   \n",
       "\n",
       "   TRAFFIC_CTRL_Stop Sign  TRAFFIC_CTRL_Traffic Signal  \\\n",
       "0                       0                            1   \n",
       "1                       0                            0   \n",
       "2                       0                            0   \n",
       "3                       0                            0   \n",
       "4                       0                            0   \n",
       "\n",
       "   MULTI_VEH_Cyclist(s)+Pedestrian(s) only  ...  STREET_LIGHT_Off  \\\n",
       "0                                        0  ...                 0   \n",
       "1                                        0  ...                 0   \n",
       "2                                        0  ...                 0   \n",
       "3                                        0  ...                 0   \n",
       "4                                        0  ...                 0   \n",
       "\n",
       "   STREET_LIGHT_On  STREET_LIGHT_Unknown  WEATHER_A_Fine  \\\n",
       "0                1                     0               1   \n",
       "1                0                     0               1   \n",
       "2                0                     0               1   \n",
       "3                0                     0               1   \n",
       "4                1                     0               1   \n",
       "\n",
       "   WEATHER_A_Heavy Rain  WEATHER_A_Light Rain  WEATHER_A_Mist  WEATHER_A_Snow  \\\n",
       "0                     0                     0               0               0   \n",
       "1                     0                     0               0               0   \n",
       "2                     0                     0               0               0   \n",
       "3                     0                     0               0               0   \n",
       "4                     0                     0               0               0   \n",
       "\n",
       "   WEATHER_A_Unknown  CRASH_SEV_CODE  \n",
       "0                  0               0  \n",
       "1                  0               0  \n",
       "2                  0               0  \n",
       "3                  0               0  \n",
       "4                  0               0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import time\n",
    "import lime\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "df = pd.read_csv(\"crash_data_one_hot_encoded_MLP.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(641070, 92)\n",
      "(33741, 92)\n"
     ]
    }
   ],
   "source": [
    "df = sklearn.utils.shuffle(df)\n",
    "X = df.drop(\"CRASH_SEV_CODE\", axis=1).values\n",
    "y = df[\"CRASH_SEV_CODE\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=40)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.71814665\n",
      "Iteration 2, loss = 0.69638344\n",
      "Iteration 3, loss = 0.69367360\n",
      "Iteration 4, loss = 0.69208548\n",
      "Iteration 5, loss = 0.69117508\n",
      "Iteration 6, loss = 0.69035189\n",
      "Iteration 7, loss = 0.68958529\n",
      "Iteration 8, loss = 0.68916463\n",
      "Iteration 9, loss = 0.68842370\n",
      "Iteration 10, loss = 0.68811231\n",
      "Iteration 11, loss = 0.68741556\n",
      "Iteration 12, loss = 0.68693451\n",
      "Iteration 13, loss = 0.68652431\n",
      "Iteration 14, loss = 0.68614609\n",
      "Iteration 15, loss = 0.68571546\n",
      "Iteration 16, loss = 0.68530634\n",
      "Iteration 17, loss = 0.68485379\n",
      "Iteration 18, loss = 0.68452543\n",
      "Iteration 19, loss = 0.68419695\n",
      "Iteration 20, loss = 0.68377660\n",
      "Iteration 21, loss = 0.68366363\n",
      "Iteration 22, loss = 0.68337385\n",
      "Iteration 23, loss = 0.68318855\n",
      "Iteration 24, loss = 0.68277196\n",
      "Iteration 25, loss = 0.68263089\n",
      "Iteration 26, loss = 0.68228817\n",
      "Iteration 27, loss = 0.68187987\n",
      "Iteration 28, loss = 0.68189536\n",
      "Iteration 29, loss = 0.68143316\n",
      "Iteration 30, loss = 0.68133388\n",
      "Iteration 31, loss = 0.68104458\n",
      "Iteration 32, loss = 0.68087819\n",
      "Iteration 33, loss = 0.68072775\n",
      "Iteration 34, loss = 0.68051800\n",
      "Iteration 35, loss = 0.68035375\n",
      "Iteration 36, loss = 0.68019704\n",
      "Iteration 37, loss = 0.67994951\n",
      "Iteration 38, loss = 0.67982273\n",
      "Iteration 39, loss = 0.67962701\n",
      "Iteration 40, loss = 0.67951071\n",
      "Iteration 41, loss = 0.67924573\n",
      "Iteration 42, loss = 0.67928836\n",
      "Iteration 43, loss = 0.67897066\n",
      "Iteration 44, loss = 0.67889594\n",
      "Iteration 45, loss = 0.67872168\n",
      "Iteration 46, loss = 0.67857817\n",
      "Iteration 47, loss = 0.67849777\n",
      "Iteration 48, loss = 0.67836003\n",
      "Iteration 49, loss = 0.67820328\n",
      "Iteration 50, loss = 0.67815285\n",
      "Iteration 51, loss = 0.67798149\n",
      "Iteration 52, loss = 0.67786529\n",
      "Iteration 53, loss = 0.67771107\n",
      "Iteration 54, loss = 0.67757323\n",
      "Iteration 55, loss = 0.67756046\n",
      "Iteration 56, loss = 0.67736719\n",
      "Iteration 57, loss = 0.67732230\n",
      "Iteration 58, loss = 0.67722318\n",
      "Iteration 59, loss = 0.67712002\n",
      "Iteration 60, loss = 0.67688341\n",
      "Iteration 61, loss = 0.67698305\n",
      "Iteration 62, loss = 0.67687554\n",
      "Iteration 63, loss = 0.67689076\n",
      "Iteration 64, loss = 0.67659931\n",
      "Iteration 65, loss = 0.67658861\n",
      "Iteration 66, loss = 0.67656354\n",
      "Iteration 67, loss = 0.67638538\n",
      "Iteration 68, loss = 0.67631412\n",
      "Iteration 69, loss = 0.67628443\n",
      "Iteration 70, loss = 0.67618444\n",
      "Iteration 71, loss = 0.67615717\n",
      "Iteration 72, loss = 0.67604132\n",
      "Iteration 73, loss = 0.67603707\n",
      "Iteration 74, loss = 0.67586847\n",
      "Iteration 75, loss = 0.67590894\n",
      "Iteration 76, loss = 0.67581728\n",
      "Iteration 77, loss = 0.67570393\n",
      "Iteration 78, loss = 0.67564477\n",
      "Iteration 79, loss = 0.67556890\n",
      "Iteration 80, loss = 0.67551116\n",
      "Iteration 81, loss = 0.67548976\n",
      "Iteration 82, loss = 0.67543081\n",
      "Iteration 83, loss = 0.67539846\n",
      "Iteration 84, loss = 0.67543084\n",
      "Iteration 85, loss = 0.67527947\n",
      "Iteration 86, loss = 0.67514947\n",
      "Iteration 87, loss = 0.67523644\n",
      "Iteration 88, loss = 0.67520469\n",
      "Iteration 89, loss = 0.67507012\n",
      "Iteration 90, loss = 0.67499047\n",
      "Iteration 91, loss = 0.67496834\n",
      "Iteration 92, loss = 0.67489261\n",
      "Iteration 93, loss = 0.67482762\n",
      "Iteration 94, loss = 0.67490100\n",
      "Iteration 95, loss = 0.67483478\n",
      "Iteration 96, loss = 0.67481149\n",
      "Iteration 97, loss = 0.67475272\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      " Training time: 577.6084218025208s\n",
      "\n",
      " training data\n",
      "\n",
      "[[     0   2012   3869      0]\n",
      " [     0  32266 110977      0]\n",
      " [     0  12782 443706      0]\n",
      " [     0  11848  23610      0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.76      0.97      0.85    456488\n",
      "           1       0.55      0.23      0.32    143243\n",
      "\n",
      "   micro avg       0.74      0.79      0.77    599731\n",
      "   macro avg       0.65      0.60      0.59    599731\n",
      "weighted avg       0.71      0.79      0.73    599731\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " test data\n",
      "\n",
      "[[    0    95   202     0]\n",
      " [    0  1581  6010     0]\n",
      " [    0   884 23080     0]\n",
      " [    0   546  1343     0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.75      0.96      0.85     23964\n",
      "           1       0.51      0.21      0.30      7591\n",
      "\n",
      "   micro avg       0.73      0.78      0.76     31555\n",
      "   macro avg       0.63      0.59      0.57     31555\n",
      "weighted avg       0.69      0.78      0.71     31555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(92,54,1), activation='relu', solver='adam', max_iter=500,verbose = True)\n",
    "\n",
    "start = time.time()\n",
    "mlp.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)\n",
    "print(f\"\\n Training time: {stop - start}s\")\n",
    "print(\"\\n training data\\n\")\n",
    "print(confusion_matrix(y_train,predict_train))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train,predict_train,labels=pd.unique(predict_train)))\n",
    "print(\"\\n---------------------------------------------------------------------------------------\\n\")\n",
    "print(\"\\n test data\\n\")\n",
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,predict_test,labels=pd.unique(predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 2.58555326e-01, -3.38508608e-01, -1.33150981e+00, ...,\n",
      "        -4.20730613e-01,  9.59247446e-01,  1.38885037e+00],\n",
      "       [ 7.81746316e-01,  5.74962594e-01, -3.42836352e-01, ...,\n",
      "        -5.14344352e-01,  1.14570581e-03, -1.46331579e+00],\n",
      "       [-1.62340146e-01,  6.89947440e-02, -7.40552627e-01, ...,\n",
      "        -4.20915930e-01, -9.83637137e-01, -5.31373349e-01],\n",
      "       ...,\n",
      "       [ 4.76842959e-01,  2.96876478e-01, -3.14333573e-01, ...,\n",
      "         2.34409831e-01,  1.69198088e-01,  9.34101083e-02],\n",
      "       [-6.09238968e-02, -8.28273988e-02,  6.95254806e-02, ...,\n",
      "        -4.79537252e-02,  1.37001155e-01,  1.30994072e-01],\n",
      "       [-8.52214293e-01,  8.24132173e-03, -3.65775236e-01, ...,\n",
      "        -8.05638398e-02, -4.21020716e-01, -1.23235797e-02]]), array([[-3.72909388e-01, -4.71243548e-01,  5.57881703e-01, ...,\n",
      "        -3.07781825e-01,  5.51285098e-01,  6.89964153e-03],\n",
      "       [-1.22971922e-01, -2.14933518e-01, -2.17075243e-01, ...,\n",
      "         1.37091290e-01,  9.36103145e-02,  3.79903712e-01],\n",
      "       [-1.56073875e-01,  2.04051776e-01,  1.04318549e-01, ...,\n",
      "        -3.64125376e-01, -1.93537164e-01, -5.27448906e-01],\n",
      "       ...,\n",
      "       [ 3.33614829e-01,  4.07231888e-02, -1.04541463e+00, ...,\n",
      "         1.04870604e-01, -1.26704274e-02, -2.46906950e+00],\n",
      "       [ 1.54423332e-01, -7.28141041e-01,  3.37138190e-01, ...,\n",
      "        -1.49025275e+00,  1.15784425e-03,  8.61819230e-02],\n",
      "       [-1.00943262e+00,  4.87949559e-01,  6.77211823e-01, ...,\n",
      "         2.89479472e-02, -1.53304897e-01,  2.28275972e-01]]), array([[ 2.70789214e-001],\n",
      "       [-1.51090869e+000],\n",
      "       [ 1.42384967e-001],\n",
      "       [ 1.32236938e-001],\n",
      "       [-3.04148831e-315],\n",
      "       [ 1.96698286e-001],\n",
      "       [-7.12246903e-001],\n",
      "       [-2.84066893e-001],\n",
      "       [ 1.45848928e-001],\n",
      "       [ 4.48649391e-001],\n",
      "       [ 1.25532820e-001],\n",
      "       [ 4.44912868e-001],\n",
      "       [ 2.04653442e-001],\n",
      "       [ 2.68870500e-316],\n",
      "       [ 1.18436526e-001],\n",
      "       [-7.75424486e-001],\n",
      "       [ 6.23364311e-001],\n",
      "       [ 1.78317158e-001],\n",
      "       [-4.09366353e-001],\n",
      "       [ 6.79612243e-002],\n",
      "       [-6.88808170e-001],\n",
      "       [ 1.05536567e+000],\n",
      "       [-3.34977689e-001],\n",
      "       [ 1.53129178e-001],\n",
      "       [ 2.52218383e-001],\n",
      "       [ 1.11987152e-001],\n",
      "       [-8.03685021e-001],\n",
      "       [ 1.15249676e-001],\n",
      "       [ 1.19692276e-001],\n",
      "       [ 1.19674723e-001],\n",
      "       [-3.92127263e-001],\n",
      "       [-4.83857938e-001],\n",
      "       [ 4.37626270e-001],\n",
      "       [-3.77282048e-001],\n",
      "       [ 1.38639356e-001],\n",
      "       [ 9.07364926e-002],\n",
      "       [-9.18282006e-001],\n",
      "       [-2.43684762e-001],\n",
      "       [-2.39065275e-001],\n",
      "       [-5.68602509e-001],\n",
      "       [ 7.57694956e-002],\n",
      "       [-5.07503223e-001],\n",
      "       [-1.08381463e+000],\n",
      "       [ 1.64750088e-001],\n",
      "       [ 1.71268531e-001],\n",
      "       [ 1.47397752e-001],\n",
      "       [ 9.85302829e-002],\n",
      "       [-7.08592588e-001],\n",
      "       [ 3.60220399e-001],\n",
      "       [ 3.87240566e-001],\n",
      "       [-1.17896003e+000],\n",
      "       [-5.61212414e-001],\n",
      "       [ 4.11638800e-001],\n",
      "       [-6.59242089e-001]]), array([[0.37193385, 0.4611153 , 0.70400705, 0.38731303]])]\n"
     ]
    }
   ],
   "source": [
    "weights =  (mlp.coefs_)\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 16288.95, NNZs: 85, Bias: -1.000000, T: 674811, Avg. loss: 36266.002777\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20229.79, NNZs: 88, Bias: -4.000000, T: 674811, Avg. loss: 209171.019945\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27231.27, NNZs: 90, Bias: -21.000000, T: 674811, Avg. loss: 698633.960251\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37119.08, NNZs: 90, Bias: 20.000000, T: 674811, Avg. loss: 814152.820191\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31386.51, NNZs: 86, Bias: 0.000000, T: 1349622, Avg. loss: 35857.828555\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22412.37, NNZs: 88, Bias: -8.000000, T: 1349622, Avg. loss: 208710.575692\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 51327.20, NNZs: 91, Bias: -42.000000, T: 1349622, Avg. loss: 696286.148209\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 69654.90, NNZs: 90, Bias: 40.000000, T: 1349622, Avg. loss: 806324.295438\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16420.41, NNZs: 87, Bias: -1.000000, T: 2024433, Avg. loss: 36781.782041\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36595.79, NNZs: 89, Bias: -11.000000, T: 2024433, Avg. loss: 208386.736836\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 75013.22, NNZs: 91, Bias: -60.000000, T: 2024433, Avg. loss: 694883.500042\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 100406.83, NNZs: 91, Bias: 58.000000, T: 2024433, Avg. loss: 804789.105421\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 11983.60, NNZs: 87, Bias: 0.000000, T: 2699244, Avg. loss: 36351.590872\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41760.65, NNZs: 89, Bias: -11.000000, T: 2699244, Avg. loss: 207785.542484\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 96728.51, NNZs: 91, Bias: -79.000000, T: 2699244, Avg. loss: 693096.966568\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 127974.78, NNZs: 92, Bias: 73.000000, T: 2699244, Avg. loss: 800611.115026\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14941.22, NNZs: 88, Bias: 0.000000, T: 3374055, Avg. loss: 36207.704322\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51270.52, NNZs: 89, Bias: -14.000000, T: 3374055, Avg. loss: 208043.453090\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 118328.54, NNZs: 91, Bias: -97.000000, T: 3374055, Avg. loss: 689681.574144\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 156412.54, NNZs: 92, Bias: 89.000000, T: 3374055, Avg. loss: 799574.945327\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18201.75, NNZs: 88, Bias: -1.000000, T: 4048866, Avg. loss: 36238.503385\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 61791.35, NNZs: 91, Bias: -15.000000, T: 4048866, Avg. loss: 207639.286701\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 138899.61, NNZs: 91, Bias: -115.000000, T: 4048866, Avg. loss: 689114.809659\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 22093.67, NNZs: 88, Bias: 0.000000, T: 4723677, Avg. loss: 36268.661127\n",
      "Total training time: 1.71 seconds.\n",
      "Convergence after 7 epochs took 1.71 seconds\n",
      "Norm: 184595.36, NNZs: 92, Bias: 106.000000, T: 4048866, Avg. loss: 796636.340675\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 68399.85, NNZs: 91, Bias: -17.000000, T: 4723677, Avg. loss: 207273.474499\n",
      "Total training time: 1.76 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 158581.61, NNZs: 91, Bias: -133.000000, T: 4723677, Avg. loss: 688194.311710\n",
      "Total training time: 1.89 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 73639.45, NNZs: 91, Bias: -18.000000, T: 5398488, Avg. loss: 207288.378882\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 206765.90, NNZs: 92, Bias: 118.000000, T: 4723677, Avg. loss: 790909.317338\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 177305.40, NNZs: 91, Bias: -149.000000, T: 5398488, Avg. loss: 685821.034291\n",
      "Total training time: 2.13 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 83535.96, NNZs: 91, Bias: -19.000000, T: 6073299, Avg. loss: 206949.418434\n",
      "Total training time: 2.20 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 229497.92, NNZs: 92, Bias: 132.000000, T: 5398488, Avg. loss: 787832.995270\n",
      "Total training time: 2.25 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 195679.80, NNZs: 92, Bias: -165.000000, T: 6073299, Avg. loss: 684556.898752\n",
      "Total training time: 2.37 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 91579.68, NNZs: 92, Bias: -19.000000, T: 6748110, Avg. loss: 207177.854113\n",
      "Total training time: 2.41 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 253948.46, NNZs: 91, Bias: 147.000000, T: 6073299, Avg. loss: 791018.642605\n",
      "Total training time: 2.52 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 96904.11, NNZs: 92, Bias: -20.000000, T: 7422921, Avg. loss: 207512.359077\n",
      "Total training time: 2.64 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 214115.68, NNZs: 92, Bias: -182.000000, T: 6748110, Avg. loss: 685424.657311\n",
      "Total training time: 2.64 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 273910.91, NNZs: 92, Bias: 159.000000, T: 6748110, Avg. loss: 779481.731125\n",
      "Total training time: 2.78 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 103005.98, NNZs: 92, Bias: -20.000000, T: 8097732, Avg. loss: 206803.525934\n",
      "Total training time: 2.86 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 231659.34, NNZs: 92, Bias: -199.000000, T: 7422921, Avg. loss: 684123.761484\n",
      "Total training time: 2.87 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 295318.50, NNZs: 92, Bias: 172.000000, T: 7422921, Avg. loss: 784950.993742\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 110314.10, NNZs: 92, Bias: -21.000000, T: 8772543, Avg. loss: 206859.792631\n",
      "Total training time: 3.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 248411.24, NNZs: 92, Bias: -215.000000, T: 8097732, Avg. loss: 681094.556307\n",
      "Total training time: 3.11 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 315235.42, NNZs: 92, Bias: 184.000000, T: 8097732, Avg. loss: 781820.407111\n",
      "Total training time: 3.26 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 119338.16, NNZs: 92, Bias: -21.000000, T: 9447354, Avg. loss: 206172.112399\n",
      "Total training time: 3.31 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 263520.26, NNZs: 92, Bias: -230.000000, T: 8772543, Avg. loss: 681819.203586\n",
      "Total training time: 3.35 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 333291.50, NNZs: 91, Bias: 197.000000, T: 8772543, Avg. loss: 775614.028858\n",
      "Total training time: 3.52 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 126564.11, NNZs: 91, Bias: -23.000000, T: 10122165, Avg. loss: 206588.178656\n",
      "Total training time: 3.55 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 278593.48, NNZs: 92, Bias: -244.000000, T: 9447354, Avg. loss: 679931.775826\n",
      "Total training time: 3.59 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 133817.31, NNZs: 91, Bias: -23.000000, T: 10796976, Avg. loss: 206325.613824\n",
      "Total training time: 3.77 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 353506.62, NNZs: 92, Bias: 210.000000, T: 9447354, Avg. loss: 779393.230588\n",
      "Total training time: 3.77 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 294593.83, NNZs: 92, Bias: -261.000000, T: 10122165, Avg. loss: 681152.892136\n",
      "Total training time: 3.82 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 139523.99, NNZs: 92, Bias: -23.000000, T: 11471787, Avg. loss: 206179.786102\n",
      "Total training time: 4.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 372279.87, NNZs: 92, Bias: 225.000000, T: 10122165, Avg. loss: 774150.685476\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 308957.51, NNZs: 92, Bias: -277.000000, T: 10796976, Avg. loss: 676071.923534\n",
      "Total training time: 4.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 146370.21, NNZs: 92, Bias: -23.000000, T: 12146598, Avg. loss: 205916.877904\n",
      "Total training time: 4.24 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 390264.64, NNZs: 92, Bias: 238.000000, T: 10796976, Avg. loss: 771748.517358\n",
      "Total training time: 4.30 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 320841.47, NNZs: 92, Bias: -292.000000, T: 11471787, Avg. loss: 674413.882404\n",
      "Total training time: 4.33 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 153029.34, NNZs: 92, Bias: -24.000000, T: 12821409, Avg. loss: 205498.775515\n",
      "Total training time: 4.48 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 408204.86, NNZs: 92, Bias: 250.000000, T: 11471787, Avg. loss: 770166.001334\n",
      "Total training time: 4.57 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 333731.75, NNZs: 92, Bias: -307.000000, T: 12146598, Avg. loss: 675563.831585\n",
      "Total training time: 4.59 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 159466.53, NNZs: 92, Bias: -25.000000, T: 13496220, Avg. loss: 205688.918945\n",
      "Total training time: 4.72 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 346717.44, NNZs: 92, Bias: -321.000000, T: 12821409, Avg. loss: 674038.434794\n",
      "Total training time: 4.82 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 424291.99, NNZs: 92, Bias: 262.000000, T: 12146598, Avg. loss: 768005.372092\n",
      "Total training time: 4.84 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 166017.63, NNZs: 92, Bias: -25.000000, T: 14171031, Avg. loss: 205220.844428\n",
      "Total training time: 4.94 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 360545.18, NNZs: 92, Bias: -339.000000, T: 13496220, Avg. loss: 677973.825228\n",
      "Total training time: 5.06 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 441800.68, NNZs: 92, Bias: 274.000000, T: 12821409, Avg. loss: 770909.939125\n",
      "Total training time: 5.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 172399.61, NNZs: 92, Bias: -26.000000, T: 14845842, Avg. loss: 205126.170220\n",
      "Total training time: 5.17 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 372182.73, NNZs: 92, Bias: -354.000000, T: 14171031, Avg. loss: 673559.548202\n",
      "Total training time: 5.30 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 459410.26, NNZs: 91, Bias: 287.000000, T: 13496220, Avg. loss: 770291.498461\n",
      "Total training time: 5.34 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 179587.66, NNZs: 92, Bias: -27.000000, T: 15520653, Avg. loss: 204761.578609\n",
      "Total training time: 5.39 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 385655.54, NNZs: 92, Bias: -370.000000, T: 14845842, Avg. loss: 675898.704025\n",
      "Total training time: 5.54 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 476712.41, NNZs: 91, Bias: 300.000000, T: 14171031, Avg. loss: 767464.493239\n",
      "Total training time: 5.62 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 185030.25, NNZs: 92, Bias: -26.000000, T: 16195464, Avg. loss: 205902.892849\n",
      "Total training time: 5.63 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 396313.63, NNZs: 92, Bias: -386.000000, T: 15520653, Avg. loss: 671378.034916\n",
      "Total training time: 5.78 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 191464.70, NNZs: 92, Bias: -26.000000, T: 16870275, Avg. loss: 205106.923743\n",
      "Total training time: 5.86 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 494857.83, NNZs: 92, Bias: 312.000000, T: 14845842, Avg. loss: 767259.658226\n",
      "Total training time: 5.87 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 406904.12, NNZs: 92, Bias: -398.000000, T: 16195464, Avg. loss: 670966.625829\n",
      "Total training time: 6.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 198227.73, NNZs: 92, Bias: -26.000000, T: 17545086, Avg. loss: 205289.673494\n",
      "Total training time: 6.09 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 507285.97, NNZs: 92, Bias: 322.000000, T: 15520653, Avg. loss: 759575.199348\n",
      "Total training time: 6.12 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 418526.56, NNZs: 92, Bias: -412.000000, T: 16870275, Avg. loss: 672111.623192\n",
      "Total training time: 6.26 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 204409.21, NNZs: 92, Bias: -26.000000, T: 18219897, Avg. loss: 205108.013382\n",
      "Total training time: 6.33 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 521098.86, NNZs: 92, Bias: 334.000000, T: 16195464, Avg. loss: 759283.394017\n",
      "Total training time: 6.36 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 429332.21, NNZs: 92, Bias: -428.000000, T: 17545086, Avg. loss: 670220.291572\n",
      "Total training time: 6.52 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 210381.23, NNZs: 92, Bias: -26.000000, T: 18894708, Avg. loss: 204915.778572\n",
      "Total training time: 6.55 seconds.\n",
      "Convergence after 28 epochs took 6.55 seconds\n",
      "Norm: 537821.44, NNZs: 92, Bias: 348.000000, T: 16870275, Avg. loss: 764725.093766\n",
      "Total training time: 6.61 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 441651.58, NNZs: 92, Bias: -444.000000, T: 18219897, Avg. loss: 671963.840379\n",
      "Total training time: 6.73 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 549681.72, NNZs: 92, Bias: 357.000000, T: 17545086, Avg. loss: 757226.566043\n",
      "Total training time: 6.83 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 449698.56, NNZs: 92, Bias: -458.000000, T: 18894708, Avg. loss: 666916.403202\n",
      "Total training time: 6.93 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 565740.12, NNZs: 92, Bias: 369.000000, T: 18219897, Avg. loss: 761822.766012\n",
      "Total training time: 7.05 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 462689.89, NNZs: 92, Bias: -474.000000, T: 19569519, Avg. loss: 672214.127492\n",
      "Total training time: 7.15 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 579590.11, NNZs: 92, Bias: 381.000000, T: 18894708, Avg. loss: 758979.328895\n",
      "Total training time: 7.27 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 474144.97, NNZs: 92, Bias: -488.000000, T: 20244330, Avg. loss: 668982.160347\n",
      "Total training time: 7.36 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 594296.22, NNZs: 92, Bias: 394.000000, T: 19569519, Avg. loss: 759542.129207\n",
      "Total training time: 7.50 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 483747.27, NNZs: 92, Bias: -503.000000, T: 20919141, Avg. loss: 667403.096359\n",
      "Total training time: 7.58 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 609722.53, NNZs: 92, Bias: 409.000000, T: 20244330, Avg. loss: 758664.863031\n",
      "Total training time: 7.73 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 494546.44, NNZs: 92, Bias: -518.000000, T: 21593952, Avg. loss: 669193.257007\n",
      "Total training time: 7.80 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 623128.25, NNZs: 92, Bias: 423.000000, T: 20919141, Avg. loss: 756057.222076\n",
      "Total training time: 7.95 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 504194.60, NNZs: 92, Bias: -533.000000, T: 22268763, Avg. loss: 667729.571332\n",
      "Total training time: 8.01 seconds.\n",
      "Convergence after 33 epochs took 8.01 seconds\n",
      "Norm: 634623.81, NNZs: 92, Bias: 435.000000, T: 21593952, Avg. loss: 749795.589083\n",
      "Total training time: 8.16 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 647683.65, NNZs: 92, Bias: 448.000000, T: 22268763, Avg. loss: 754907.801346\n",
      "Total training time: 8.36 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 659965.63, NNZs: 92, Bias: 463.000000, T: 22943574, Avg. loss: 753003.505822\n",
      "Total training time: 8.56 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 674006.29, NNZs: 92, Bias: 475.000000, T: 23618385, Avg. loss: 756806.159557\n",
      "Total training time: 8.76 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 687450.10, NNZs: 92, Bias: 489.000000, T: 24293196, Avg. loss: 753043.794904\n",
      "Total training time: 8.96 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 699986.26, NNZs: 92, Bias: 503.000000, T: 24968007, Avg. loss: 750598.465324\n",
      "Total training time: 9.17 seconds.\n",
      "Convergence after 37 epochs took 9.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    9.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    9.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=40, verbose=True,n_jobs = -1)\n",
    "clf.fit(X, y)\n",
    "\n",
    "coeffs = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      " min:  -4847.0  feature:  NUM_LANES \n",
      " max:  17190.0  feature:  SPD_LIM\n",
      "-------------------\n",
      "-------------------\n",
      " min:  -376926.0  feature:  MULTI_VEH_Multi vehicle \n",
      " max:  211287.0  feature:  MULTI_VEH_Vehicle(s)+Pedestrian(s)\n",
      "-------------------\n",
      "-------------------\n",
      " min:  -349098.0  feature:  MULTI_VEH_Vehicle(s)+Pedestrian(s) \n",
      " max:  472311.0  feature:  MULTI_VEH_Multi vehicle\n",
      "-------------------\n",
      "-------------------\n",
      " min:  -131925.0  feature:  MULTI_VEH_Multi vehicle \n",
      " max:  98814.0  feature:  MULTI_VEH_Vehicle(s)+Pedestrian(s)\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "features = df.columns\n",
    "minV = 0\n",
    "maxV = 0\n",
    "minPlace = 0\n",
    "maxPlace = 0\n",
    "count = 0\n",
    "for i in coeffs:\n",
    "    for j in i:\n",
    "        if count == 0:\n",
    "            minPlace = 0\n",
    "            maxPlace = 0\n",
    "            minV = j\n",
    "            maxV = j\n",
    "        else:\n",
    "            if minV > j:\n",
    "                minV =j\n",
    "                minPlace = count\n",
    "            if maxV < j:\n",
    "                maxV = j\n",
    "                maxPlace = count\n",
    "        count+=1\n",
    "    \n",
    "    count = 0\n",
    "    print(\"-------------------\")\n",
    "    print(\" min: \",minV,\" feature: \",features[minPlace],\"\\n max: \",maxV,\" feature: \",features[maxPlace])\n",
    "    print(\"-------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
